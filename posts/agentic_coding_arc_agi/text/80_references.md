## References

[1] [On the Measure of Intelligence](https://arxiv.org/abs/1911.01547)
[2] [OpenAI o3 breakthrough high score on ARC-AGI-PUB](https://arcprize.org/blog/oai-o3-pub-breakthrough)
[3] [ARC-AGI-2 Overview With Francois Chollet](https://www.youtube.com/watch?v=TWHezX43I-4)
[4] [ARC-AGI-2: A New Challenge for Frontier AI Reasoning Systems](https://arxiv.org/abs/2505.11831)
[5] [ARC Prize 2025: Technical Report](https://arxiv.org/abs/2601.10904)
[6] [Introducing o3 and o4-mini (See "Toward agentic tool use" section and corresponding example traces)](https://openai.com/index/introducing-o3-and-o4-mini/)
[7] [gpt-oss-120b & gpt-oss-20b Model Card](https://arxiv.org/abs/2508.10925)
[8] [The Emperor Has No Clothes: How to Code Claude Code in 200 Lines of Code](https://www.mihaileric.com/The-Emperor-Has-No-Clothes/)
[9] [Getting 50% (SoTA) on ARC-AGI with GPT-4o](https://blog.redwoodresearch.org/p/getting-50-sota-on-arc-agi-with-gpt)
[10] [Reasoning models don't always say what they think](https://www.anthropic.com/research/reasoning-models-dont-say-think)
[11] [Interleaved Thinking - VLLM Docs](https://docs.vllm.ai/en/stable/features/interleaved_thinking/)
[12] [Interleaved Thinking - Claude Docs (See the comparative example in "Tool use without interleaved thinking" and "Tool use with interleaved thinking")](https://platform.claude.com/docs/en/build-with-claude/extended-thinking#interleaved-thinking)
[13] [Differences in thinking across Claude model versions](https://platform.claude.com/docs/en/build-with-claude/extended-thinking#differences-in-thinking-across-model-versions)
[14] [Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities](https://arxiv.org/abs/2507.06261)
[15] [Interleaved Thinking - Z.AI Developer Documentation](https://docs.z.ai/guides/capabilities/thinking-mode#interleaved-thinking)
[16] [Interleaved Thinking Unlocks Reliable MiniMax-M2 Agentic Capability](https://www.minimax.io/news/why-is-interleaved-thinking-important-for-m2)
[17] [Introducing Kimi K2 Thinking](https://moonshotai.github.io/Kimi-K2/thinking.html)
[18] [The Bitter Lesson](http://www.incompleteideas.net/IncIdeas/BitterLesson.html)
[19] [ARC Prize Verified - Official Testing Policy](https://arcprize.org/policy)
[20] [Scoring script in the official ARC AGI Benchmarking repository](https://github.com/arcprize/arc-agi-benchmarking/blob/main/src/arc_agi_benchmarking/scoring/scoring.py)
[21] [Official GPT 5.2 XHigh Results - Huggingface](https://huggingface.co/datasets/arcprize/arc_agi_v2_public_eval/blob/main/gpt-5-2-2025-12-11-thinking-xhigh/results.json)
[22] [Icecuber's 1st place solution + code and official documentation](https://www.kaggle.com/competitions/abstraction-and-reasoning-challenge/writeups/icecuber-1st-place-solution-code-and-official-docu)
[23] [How I came in first on ARC-AGI-Pub using Sonnet 3.5 with Evolutionary Test-time Compute](https://jeremyberman.substack.com/p/how-i-got-a-record-536-on-arc-agi)
[24] [ARC Prize 2025 Results & Analysis](https://arcprize.org/blog/arc-prize-2025-results-analysis)
[25] [Wider or Deeper? Scaling LLM Inference-Time Compute with Adaptive Branching Tree Search](https://arxiv.org/abs/2503.04412)
[26] [How I got the highest score on ARC-AGI again swapping Python for English](https://jeremyberman.substack.com/p/how-i-got-the-highest-score-on-arc-agi-again)
[27] [Poetiq Shatters ARC-AGI-2 State of the Art at Half the Cost](https://poetiq.ai/posts/arcagi_verified/)
[28] [GPT 5.2 System Card](https://openai.com/index/gpt-5-system-card-update-gpt-5-2/)
[29] [Provider Variance: Introducing Exacto](https://openrouter.ai/announcements/provider-variance-introducing-exacto)
[30] [gpt-oss-120b tool calls - GitHub issue on VLLM repository](https://github.com/vllm-project/vllm/issues/22337)
[31] [MALFORMED_FUNCTION_CALL finish reason happens too frequently with vertex AI - Build with Google AI Forum](https://discuss.ai.google.dev/t/malformed-function-call-finish-reason-happens-too-frequently-with-vertex-ai/93630)
[32] [K2-Vendor-Verifier](https://github.com/MoonshotAI/K2-Vendor-Verifier)
[33] [GPT 5.2 Xhigh Score with the Poetiq Harness](https://x.com/poetiq_ai/status/2003546910427361402?s=20)
[34] [Code repository that allows reproducing the results in this post](https://github.com/gutfeeling/arc-agi-2-submission)
[35] [Data from the experiments in this post](https://huggingface.co/datasets/arcagi2/arcagi2-agentic-coding-publication)
[36] [Does Reinforcement Learning Really Incentivize Reasoning Capacity in LLMs Beyond the Base Model?](https://arxiv.org/abs/2504.13837)
[37] [Responses API patch that we used to reliably elicit interleaved thinking in GPT OSS 120B](https://github.com/gutfeeling/arc-agi-2-submission/blob/master/src/vllm_patch/harmony_utils.py)
